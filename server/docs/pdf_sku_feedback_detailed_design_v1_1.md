# Feedback æ¨¡å—è¯¦ç»†è®¾è®¡

> **æ–‡æ¡£ç‰ˆæœ¬**: V1.1  
> **ä¸Šæ¸¸ä¾èµ–**: TA V1.6 Â§3.8 | BA V1.1 Â§4.8 | BRD V2.1 Â§11  
> **æ¨¡å—å®šä½**: é—­ç¯åé¦ˆ â€” æ ‡æ³¨é‡‡é›† â†’ é˜ˆå€¼æ ¡å‡† â†’ å±æ€§å‡çº§  
> **è®¾è®¡åŸåˆ™**: æ•°æ®é©±åŠ¨è‡ªåŠ¨æ ¡å‡†ã€å‡çº§éœ€äººå·¥ç¡®è®¤ã€ä¸ç ´ååœ¨é€” Job

### V1.1 ä¿®è®¢è¯´æ˜

| å˜æ›´ ID | çº§åˆ« | è¯´æ˜ | æ¥æº |
|---------|------|------|------|
| P0-1 | P0 | æ ¡å‡†å®‰å…¨æŠ¤æ ï¼šÂ±10% é™å¹… + æ ·æœ¬é‡é—¨æ§› + å¼‚å¸¸æ£€æµ‹ | Gemini |
| P1-FC1 | P1 | Few-shot å…¥åº“åŒäººå…±è¯†ï¼ˆâ‰¥2 åé«˜åˆ†æ ‡æ³¨å‘˜ä¸€è‡´ï¼‰ | Gemini |
| P1-FC2 | P1 | æ ¡å‡†è§¦å‘æœ€å°æ ·æœ¬é‡åŠ¨æ€ç­–ç•¥ | ChatGPT |
| P1-FC3 | P1 | å®¡æ‰¹ä¸ Config è”åŠ¨ç»†èŠ‚ | DeepSeek |
| P1-FC4 | P1 | æ ¡å‡†å®¡æ‰¹ SLAï¼ˆ48h æœªå®¡æ‰¹è‡ªåŠ¨æé†’ï¼‰ | Kimi |

---

## 1. æ¨¡å—èŒè´£è¾¹ç•Œ

| èŒè´£ | è¯´æ˜ | å¯¹é½ |
|------|------|------|
| **æ ‡æ³¨é‡‡é›†** | äººå·¥å®Œæˆåç»“æ„åŒ–è®°å½•å†™å…¥ annotations è¡¨ï¼ˆ8ç§ç±»å‹ï¼‰ | V1.6:P0-4, BA Â§4.8 |
| **Few-shot åŒæ­¥** | ä¼˜è´¨æ ‡æ³¨æ ·æœ¬åŒæ­¥è‡³ annotation_examples è¡¨ | T36 |
| **æ ¡å‡†è§¦å‘** | æ¯æ—¥ 03:00 æ£€æŸ¥è¿‘ 7 å¤©æ ‡æ³¨é‡ > 50 â†’ è‡ªåŠ¨æ ¡å‡† | TA Â§3.8 |
| **æ ¡å‡†å¼•æ“** | AI è¾“å‡º vs äººå·¥ä¿®æ­£åå·®åˆ†æ â†’ å»ºè®®é˜ˆå€¼è°ƒæ•´ | V1.6:P1-2 |
| **å±æ€§å‡çº§** | å“ç±»å†…åŒä¸€éæ ‡å±æ€§ç¡®è®¤ â‰¥20 æ¬¡ â†’ å»ºè®®çº³å…¥ required_fields | BR-21, V1.6:P0-4 |

### 8 ç§ Annotation ç±»å‹

| ç±»å‹ | è¯´æ˜ |
|------|------|
| PAGE_TYPE_CORRECTION | é¡µé¢åˆ†ç±»ä¿®æ­£ |
| TEXT_ROLE_CORRECTION | æ–‡æœ¬è§’è‰²ä¿®æ­£ |
| IMAGE_ROLE_CORRECTION | å›¾ç‰‡è§’è‰²ä¿®æ­£ |
| SKU_ATTRIBUTE_CORRECTION | SKU å±æ€§ä¿®æ­£ |
| BINDING_CORRECTION | ç»‘å®šå…³ç³»ä¿®æ­£ |
| CUSTOM_ATTR_CONFIRM | éæ ‡å±æ€§ç¡®è®¤ |
| NEW_TYPE_REPORT | æ–°ç±»å‹ä¸ŠæŠ¥ |
| LAYOUT_CORRECTION | ç‰ˆé¢ç±»å‹ä¿®æ­£ |

### ä¾èµ–

```mermaid
graph LR
    CO[Collaboration] -->|"task completed"| FB[Feedback]
    FB --> DB[(PostgreSQL<br/>annotations<br/>calibration_records<br/>annotation_examples)]
    FB -.->|"å»ºè®®è°ƒæ•´"| CFG[Config]
    FB --> LLM[LLM Adapter<br/>Few-shot åº“]
    style FB fill:#1a1f2c,stroke:#FB923C,color:#E2E8F4
```

---

## 2. ç›®å½•ç»“æ„

```
app/
â”œâ”€â”€ feedback/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ annotation_collector.py     # æ ‡æ³¨é‡‡é›† + å½’ä¸€åŒ–
â”‚   â”œâ”€â”€ few_shot_syncer.py          # ä¼˜è´¨æ ·æœ¬ â†’ annotation_examples
â”‚   â”œâ”€â”€ calibration_engine.py       # åå·®åˆ†æ + é˜ˆå€¼å»ºè®®
â”‚   â”œâ”€â”€ attr_promotion_checker.py   # éæ ‡å±æ€§å‡çº§æ£€æŸ¥
â”‚   â”œâ”€â”€ schemas.py
â”‚   â”œâ”€â”€ repository.py
â”‚   â””â”€â”€ constants.py
```

---

## 3. æ ¸å¿ƒæ—¶åºå›¾

### 3.1 æ ‡æ³¨é‡‡é›† + Few-shot åŒæ­¥

```mermaid
sequenceDiagram
    autonumber
    participant CO as Collaboration
    participant AC as AnnotationCollector
    participant FS as FewShotSyncer
    participant DB as PostgreSQL

    CO->>+AC: collect(task_id, annotations[])
    
    loop æ¯æ¡ annotation
        AC->>AC: å½’ä¸€åŒ– payload (æŒ‰ type æ ¡éªŒ)
        AC->>DB: INSERT INTO annotations
    end

    AC->>+FS: sync_if_qualified(annotations)
    loop æ¯æ¡ annotation
        FS->>FS: è´¨é‡è¯„åˆ†(accuracy_rate Ã— rework=0)
        alt quality_score â‰¥ 0.85
            FS->>DB: UPSERT INTO annotation_examples<br/>{task_type, category, input, output, quality_score, is_confirmed=true}
        end
    end
    FS-->>-AC: synced_count

    AC-->>-CO: done
```

### 3.2 æ ¡å‡† + å±æ€§å‡çº§ï¼ˆå®šæ—¶ä»»åŠ¡ï¼‰

```mermaid
sequenceDiagram
    autonumber
    participant Cron as APScheduler
    participant CE as CalibrationEngine
    participant APC as AttrPromotionChecker
    participant DB as PostgreSQL
    participant CFG as Config Module

    rect rgb(30, 40, 60)
    Note over Cron,CE: æ¯æ—¥ 03:00 â€” é˜ˆå€¼æ ¡å‡†
    Cron->>+CE: check_and_calibrate()
    CE->>DB: SELECT COUNT(*) FROM annotations<br/>WHERE annotated_at > now()-7d
    alt count < 50
        CE-->>Cron: skip (æ•°æ®ä¸è¶³)
    else count â‰¥ 50
        CE->>DB: SELECT type, payload<br/>FROM annotations WHERE annotated_at > now()-7d
        CE->>CE: åå·®åˆ†æï¼š<br/>AI page_type vs äººå·¥ä¿®æ­£ â†’ confusion matrix<br/>AI confidence åˆ†å¸ƒ vs å®é™…å‡†ç¡®ç‡
        CE->>CE: å»ºè®®ï¼šB ä¸Šè°ƒ 0.05 / A ä¸‹è°ƒ 0.03
        CE->>DB: INSERT INTO calibration_records<br/>{analysis, suggestion, status='PENDING'}
        Note over CE: å»ºè®®éœ€äººå·¥å®¡æ‰¹å<br/>é€šè¿‡ Config API ç”Ÿæ•ˆ
    end
    CE-->>-Cron: done
    end

    rect rgb(40, 30, 50)
    Note over Cron,APC: æ¯æ—¥ 02:00 â€” å±æ€§å‡çº§
    Cron->>+APC: check_promotions()
    APC->>DB: SELECT payload->>'attr_name' AS attr,<br/>category, COUNT(*)<br/>FROM annotations<br/>WHERE type='CUSTOM_ATTR_CONFIRM'<br/>GROUP BY attr, category<br/>HAVING COUNT(*) >= 20
    loop æ¯ä¸ªå€™é€‰å±æ€§
        APC->>DB: INSERT INTO calibration_records<br/>{type='ATTR_PROMOTION', suggestion, status='PENDING'}
        Note over APC: è¿è¥å®¡æ‰¹åï¼š<br/>Config.category_schema.required_fields += attr
    end
    APC-->>-Cron: candidates_count
    end
```

---

## 4. ç»„ä»¶è¯¦ç»†è§„æ ¼

### 4.1 CalibrationEngine â€” åå·®åˆ†æ

```python
class CalibrationEngine:
    """
    [V1.1] å˜æ›´ï¼š
    - P0-1: æ ¡å‡†å®‰å…¨æŠ¤æ 
      â‘  å•æ¬¡é˜ˆå€¼å˜åŠ¨ä¸å¾—è¶…è¿‡ Â±10%ï¼ˆç¡¬é™åˆ¶ï¼‰
      â‘¡ æ ·æœ¬é‡ < MIN_SAMPLES ä¸”æ ‡æ³¨å‘˜æ•° < MIN_ANNOTATORS æ—¶ä¸è§¦å‘
      â‘¢ æ ‡æ³¨åˆ†å¸ƒåç§»ï¼ˆKL æ•£åº¦ > é˜ˆå€¼ï¼‰æ—¶æŠ¥è­¦è€Œéè‡ªåŠ¨å»ºè®®
    - P1-FC2: MIN_SAMPLES å¯é…ç½®ï¼ˆä» Config è¯»å–ï¼‰
    - P1-FC3: å®¡æ‰¹ä¸ Config è”åŠ¨ï¼šå»ºè®®ç”Ÿæˆåè‡ªåŠ¨æ¨é€åˆ°è¿è¥åå°
    - P1-FC4: å®¡æ‰¹ SLA â€” PENDING è¶… 48h è‡ªåŠ¨æé†’è¿è¥
    """

    ANALYSIS_WINDOW_DAYS = 7
    MAX_THRESHOLD_DRIFT = 0.10      # [V1.1 P0-1] Â±10% é™å¹…
    MIN_ANNOTATORS = 3              # [V1.1 P0-1] æœ€å°‘æ ‡æ³¨å‘˜æ•°
    KL_DIVERGENCE_THRESHOLD = 0.5   # [V1.1 P0-1] åˆ†å¸ƒåç§»æŠ¥è­¦é˜ˆå€¼
    APPROVAL_SLA_HOURS = 48         # [V1.1 P1-FC4] å®¡æ‰¹è¶…æ—¶æé†’

    async def check_and_calibrate(self):
        # [V1.1 P1-FC2] MIN_SAMPLES ä» Config åŠ¨æ€è¯»å–
        min_samples = config.get_value("calibration_min_samples", default=50)

        cutoff = datetime.utcnow() - timedelta(days=self.ANALYSIS_WINDOW_DAYS)
        count = await self._repo.count_recent_annotations(cutoff)
        if count < min_samples:
            return

        # [V1.1 P0-1] æœ€å°‘æ ‡æ³¨å‘˜æ•°æ£€æŸ¥
        annotator_count = await self._repo.count_distinct_annotators(cutoff)
        if annotator_count < self.MIN_ANNOTATORS:
            logger.info("calibration_skipped_few_annotators",
                count=annotator_count, min=self.MIN_ANNOTATORS)
            return

        annotations = await self._repo.get_recent_annotations(cutoff)
        suggestions = []

        # 1. é¡µé¢åˆ†ç±»åå·®
        page_corrections = [a for a in annotations if a.type == "PAGE_TYPE_CORRECTION"]
        if page_corrections:
            confusion = self._build_confusion_matrix(page_corrections)
            accuracy = self._calc_accuracy(confusion)
            if accuracy < 0.85:
                suggestions.append({
                    "action": "review_classify_prompt",
                    "accuracy": accuracy, "confusion": confusion})

        # 2. ç½®ä¿¡åº¦æ ¡å‡†
        sku_corrections = [a for a in annotations if a.type == "SKU_ATTRIBUTE_CORRECTION"]
        if sku_corrections:
            bias = self._analyze_confidence_bias(sku_corrections)

            # [V1.1 P0-1] å®‰å…¨æŠ¤æ ï¼šé™å¹… + å¼‚å¸¸æ£€æµ‹
            if abs(bias.threshold_drift) > self.MAX_THRESHOLD_DRIFT:
                logger.warning("calibration_drift_clamped",
                    raw_drift=bias.threshold_drift,
                    clamped=self.MAX_THRESHOLD_DRIFT)
                bias.threshold_drift = max(-self.MAX_THRESHOLD_DRIFT,
                    min(self.MAX_THRESHOLD_DRIFT, bias.threshold_drift))

            # [V1.1 P0-1] KL æ•£åº¦å¼‚å¸¸æ£€æµ‹
            kl_div = self._compute_kl_divergence(sku_corrections)
            if kl_div > self.KL_DIVERGENCE_THRESHOLD:
                logger.error("calibration_distribution_anomaly",
                    kl_divergence=kl_div, threshold=self.KL_DIVERGENCE_THRESHOLD)
                metrics.calibration_anomaly_total.inc()
                # æŠ¥è­¦ä½†ä¸ç”Ÿæˆå»ºè®®
                return

            if abs(bias.threshold_drift) > 0.02:
                suggestions.append({
                    "action": "adjust_thresholds",
                    "current_B": bias.current_B,
                    "suggested_B": bias.current_B + bias.threshold_drift,
                    "drift_clamped": abs(bias.threshold_drift) >= self.MAX_THRESHOLD_DRIFT,
                })

        if not suggestions:
            return

        # 3. è®°å½•å»ºè®®ï¼ˆéœ€äººå·¥å®¡æ‰¹ï¼‰
        record = CalibrationRecord(
            analysis_window=f"{cutoff.date()} ~ {date.today()}",
            sample_count=count,
            annotator_count=annotator_count,
            suggestions=suggestions,
            status="PENDING",
        )
        await self._repo.save_calibration(record)
        metrics.calibration_triggered_total.inc()

        # [V1.1 P1-FC3] æ¨é€åˆ°è¿è¥åå°å®¡æ‰¹é˜Ÿåˆ—
        await self._notify_ops_approval(record)

    async def check_approval_sla(self):
        """
        [V1.1 P1-FC4] å®šæ—¶æ£€æŸ¥ï¼šPENDING è¶… 48h è‡ªåŠ¨æé†’è¿è¥
        """
        stale = await self._repo.get_stale_pending_calibrations(
            self.APPROVAL_SLA_HOURS)
        for record in stale:
            await self._notifier.send(
                channel="ops",
                message=f"âš ï¸ æ ¡å‡†å»ºè®® #{record.id} å·²è¶… {self.APPROVAL_SLA_HOURS}h æœªå®¡æ‰¹",
                level="WARNING")
            metrics.calibration_approval_reminder_total.inc()

    async def _notify_ops_approval(self, record):
        """[V1.1 P1-FC3] æ¨é€å®¡æ‰¹é€šçŸ¥åˆ°è¿è¥åå°"""
        await self._notifier.send(
            channel="ops",
            message=f"ğŸ“Š æ–°æ ¡å‡†å»ºè®® #{record.id}ï¼š{len(record.suggestions)} æ¡å˜æ›´å¾…å®¡æ‰¹",
            level="INFO",
            action_url=f"/admin/calibration/{record.id}/review")

    def _compute_kl_divergence(self, corrections) -> float:
        """[V1.1 P0-1] è®¡ç®—æ ‡æ³¨åˆ†å¸ƒä¸ AI é¢„æµ‹åˆ†å¸ƒçš„ KL æ•£åº¦"""
        from collections import Counter
        import math
        ai_dist = Counter(c.payload.get("ai_confidence_bucket") for c in corrections)
        human_dist = Counter(c.payload.get("corrected_confidence_bucket") for c in corrections)
        total = sum(ai_dist.values()) or 1
        kl = 0.0
        for key in set(ai_dist) | set(human_dist):
            p = (ai_dist.get(key, 0) + 1) / (total + len(ai_dist))
            q = (human_dist.get(key, 0) + 1) / (total + len(human_dist))
            kl += p * math.log(p / q)
        return kl

    def _build_confusion_matrix(self, corrections):
        matrix = {}
        for c in corrections:
            ai = c.payload.get("ai_page_type")
            human = c.payload.get("corrected_page_type")
            key = (ai, human)
            matrix[key] = matrix.get(key, 0) + 1
        return matrix
```

### 4.2 AttrPromotionChecker â€” å±æ€§å‡çº§

```python
class AttrPromotionChecker:
    PROMOTION_THRESHOLD = 20  # åŒå“ç±»åŒå±æ€§ç¡®è®¤ â‰¥20 æ¬¡

    async def check_promotions(self) -> list[dict]:
        candidates = await self._repo.get_promotion_candidates(
            self.PROMOTION_THRESHOLD)
        
        results = []
        for c in candidates:
            record = CalibrationRecord(
                type="ATTR_PROMOTION",
                suggestions={
                    "category": c.category,
                    "attr_name": c.attr_name,
                    "confirm_count": c.count,
                    "action": f"Add '{c.attr_name}' to {c.category}.required_fields",
                },
                status="PENDING",
            )
            await self._repo.save_calibration(record)
            results.append(record)
        
        return results
```

### 4.3 FewShotSyncer

```python
class FewShotSyncer:
    """
    [V1.1 P1-FC1] Few-shot å…¥åº“åŒäººå…±è¯†ï¼š
    åŒä¸€ç±»å‹+åŒä¸€å“ç±»çš„æ ·æœ¬éœ€ â‰¥2 åé«˜åˆ†æ ‡æ³¨å‘˜è¾¾æˆä¸€è‡´æ–¹å¯å…¥åº“ã€‚
    é˜²æ­¢å•ä¸ªé”™è¯¯æ ‡æ³¨æ±¡æŸ“ Few-shot åº“ã€‚
    """

    QUALITY_THRESHOLD = 0.85
    MIN_CONSENSUS_COUNT = 2  # [V1.1 P1-FC1]

    async def sync_if_qualified(self, annotations: list, task: HumanTask):
        annotator_profile = await self._profiler.get_profile(task.assigned_to)
        base_quality = annotator_profile.accuracy_rate

        for ann in annotations:
            quality = base_quality * (1.0 if task.rework_count == 0 else 0.7)
            if quality < self.QUALITY_THRESHOLD:
                continue

            # [V1.1 P1-FC1] åŒäººå…±è¯†æ£€æŸ¥
            consensus_key = f"{ann.type}:{ann.payload.get('category', 'default')}"
            consensus_count = await self._repo.count_consensus(
                consensus_key,
                output_hash=self._hash_output(ann.payload),
                min_quality=self.QUALITY_THRESHOLD)

            if consensus_count + 1 >= self.MIN_CONSENSUS_COUNT:
                await self._repo.upsert_example(
                    task_type=ann.type,
                    category=ann.payload.get("category"),
                    input_context=ann.payload.get("input_context", ""),
                    output_json=ann.payload,
                    quality_score=quality,
                    is_confirmed=True,
                    consensus_count=consensus_count + 1,
                )
                metrics.few_shot_synced_total.inc()
            else:
                # è®°å½•å€™é€‰ï¼ˆç­‰å¾…ç¬¬äºŒäººç¡®è®¤ï¼‰
                await self._repo.save_consensus_candidate(
                    consensus_key=consensus_key,
                    output_hash=self._hash_output(ann.payload),
                    annotator_id=task.assigned_to,
                    quality_score=quality,
                    payload=ann.payload)

    def _hash_output(self, payload: dict) -> str:
        """å¯¹è¾“å‡ºå†…å®¹åšå“ˆå¸Œï¼ˆå¿½ç•¥å…ƒæ•°æ®å­—æ®µï¼‰ï¼Œç”¨äºå…±è¯†åŒ¹é…"""
        import hashlib
        canonical = json.dumps(
            {k: v for k, v in sorted(payload.items())
             if k not in ("annotator", "timestamp", "task_id")},
            ensure_ascii=False)
        return hashlib.sha256(canonical.encode()).hexdigest()[:16]
```

---

## 5. å®šæ—¶ä»»åŠ¡

| ä»»åŠ¡ | æ—¶é—´ | é” | è¯´æ˜ | V1.1 å˜æ›´ |
|------|------|-----|------|----------|
| å±æ€§å‡çº§æ£€æŸ¥ | 02:00 | Redis lock | éæ ‡å±æ€§é¢‘æ¬¡ç»Ÿè®¡ | â€” |
| é˜ˆå€¼æ ¡å‡† | 03:00 | Redis lock | åå·®åˆ†æ + å»ºè®® | P0-1 å®‰å…¨æŠ¤æ  |
| å®¡æ‰¹è¶…æ—¶æé†’ | 06:00 | Redis lock | [V1.1 P1-FC4] PENDING >48h æé†’ | ğŸ†• |

---

## 6. Prometheus æŒ‡æ ‡

```python
annotation_collected_total = Counter("annotation_collected_total", "", ["type"])
few_shot_synced_total = Counter("few_shot_synced_total", "")
calibration_triggered_total = Counter("calibration_triggered_total", "")
attr_promotion_candidate_total = Counter("attr_promotion_candidate_total", "", ["category"])
# [V1.1] æ–°å¢
calibration_anomaly_total = Counter("calibration_anomaly_total", "KL divergence exceeded")
calibration_drift_clamped_total = Counter("calibration_drift_clamped_total", "Drift clamped to Â±10%")
calibration_approval_reminder_total = Counter("calibration_approval_reminder_total", "")
few_shot_consensus_pending_total = Counter("few_shot_consensus_pending_total", "Awaiting 2nd consensus")
```

---

## 7. äº¤ä»˜æ¸…å•

| æ–‡ä»¶ | è¡Œæ•°(ä¼°) | ä¼˜å…ˆçº§ | V1.1 å˜æ›´ |
|------|---------|--------|----------|
| `annotation_collector.py` | ~100 | P0 | â€” |
| `few_shot_syncer.py` | ~130 | P0 | +50: åŒäººå…±è¯† |
| `calibration_engine.py` | ~350 | P1 | +150: å®‰å…¨æŠ¤æ /KLæ•£åº¦/å®¡æ‰¹è”åŠ¨/SLA |
| `attr_promotion_checker.py` | ~80 | P1 | â€” |
| `schemas.py` | ~80 | P0 | +20: ConsensusCandidate |
| `repository.py` | ~110 | P0 | +30: consensus è¡¨ CRUD |
| `constants.py` | ~30 | P0 | +10 |
| **æ€»è®¡** | **~880** | â€” | **+260ï¼ˆV1.0: 620 â†’ V1.1: 880ï¼‰** |
