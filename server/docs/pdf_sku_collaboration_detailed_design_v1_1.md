# Collaboration æ¨¡å—è¯¦ç»†è®¾è®¡

> **æ–‡æ¡£ç‰ˆæœ¬**: V1.1  
> **ä¸Šæ¸¸ä¾èµ–**: TA V1.6 Â§3.5 | BA V1.1 Â§5.4 | BRD V2.1 Â§7  
> **æ¨¡å—å®šä½**: äººæœºåä½œ â€” ä»»åŠ¡åˆ›å»º/åˆ†é…/é”/å¿ƒè·³/SLAå‡çº§/å›é€€/æ ‡æ³¨é‡‡é›†  
> **è®¾è®¡åŸåˆ™**: DB ä¸ºé”**å”¯ä¸€**æƒå¨æ¥æºã€SKIP LOCKED å¹¶å‘å®‰å…¨ã€å®å¯è¶…æ—¶ä¹Ÿä¸ä¸¢ä»»åŠ¡

### V1.1 ä¿®è®¢è¯´æ˜

| å˜æ›´ ID | çº§åˆ« | è¯´æ˜ | æ¥æº |
|---------|------|------|------|
| P1-C1 | P1 | è·¨é¡µè¡¨æ ¼è™šæ‹Ÿé•¿å›¾ + è·¨é¡µ SKU å›æº¯ API | Gemini+Qwen3 |
| P1-C2 | P1 | SLA ç†”æ–­å¢åŠ äººå·¥é€šçŸ¥ï¼ˆä¼å¾®/é’‰é’‰ï¼‰ | Qwen3 |
| P1-C3 | P1 | revert å®¡è®¡å¢åŠ  operator/reason | Qwen3 |
| P1-C4 | P1 | binding_candidates é€ä¼ è‡³ UI + è½åº“ | Qwen3 |
| P1-C5 | P1 | LockManager å¿ƒè·³ä¸ DB æ›´æ–°åŸå­æ€§ | Kimi |
| P1-C6 | P1 | AUTO_SLA æŠ½æ · 5% äººå·¥å¤æ ¸ | Kimi |
| P1-C7 | P1 | SLA L3 confidence é˜ˆå€¼ä» Config è¯»å– | GLM-5 |
| P1-C8 | P1 | ä»»åŠ¡é‡å…¥ä¸Šé™ï¼ˆrework_countâ‰¥5 å¼ºåˆ¶ SKIPPEDï¼‰ | GLM-5 |
| P1-C9 | P1 | DB ä¸ºé”å”¯ä¸€æƒå¨æ˜¾å¼å£°æ˜ | Qwen3 |
| P1-C10 | P1 | AnnotatorProfiler å½’å±æœ¬æ¨¡å— + æ•°æ®ç»“æ„ | GLM-5 |

---

## 1. æ¨¡å—èŒè´£è¾¹ç•Œ

| èŒè´£ | è¯´æ˜ | å¯¹é½ |
|------|------|------|
| **ä»»åŠ¡åˆ›å»º** | Pipeline ä½ç½®ä¿¡åº¦/æ­§ä¹‰ â†’ åˆ›å»º HumanTask + ä¸Šä¸‹æ–‡å¢å¼ºï¼ˆå‰åé¡µ+æ–‡æ¡£å±æ€§ï¼‰ | V1.6:P1-4 |
| **æ™ºèƒ½æ´¾å•** | æ ‡æ³¨å‘˜èƒ½åŠ›ç”»åƒ Ã— ä»»åŠ¡éš¾åº¦ â†’ åŠ æƒè¯„åˆ†åŒ¹é… | T79 |
| **é”ç®¡ç†** | SKIP LOCKED é¢†å–ã€DB å…ˆå†™é”ã€å¿ƒè·³ä¿æ´»ã€è¶…æ—¶é‡Šæ”¾ | V1.6:P1-18 |
| **SLA å››çº§ç†”æ–­** | 15min æä¼˜å…ˆçº§ â†’ 30min é€šçŸ¥ä¸»ç®¡ â†’ 2h AI å…œåº• â†’ 3h éƒ¨åˆ†æ¥å— | T73/Q2 |
| **ä»»åŠ¡å›é€€** | ç»„é•¿è§’è‰²æ’¤é”€ COMPLETED/SKIPPED â†’ CREATED (rework_count++) | T76 |
| **æ ‡æ³¨é‡‡é›†** | 8 ç§ annotation ç±»å‹ï¼ˆBA Â§4.8ï¼‰ï¼Œä¼˜è´¨æ ·æœ¬å…¥ few-shot åº“ | V1.6:P0-4 |
| **å®¡è®¡æ—¥å¿—** | æ‰€æœ‰çŠ¶æ€è½¬æ¢å†™ state_transitions è¡¨ | T46 |

### ä¾èµ–

```mermaid
graph LR
    PL[Pipeline] -->|"create_task"| CO[Collaboration]
    CO --> DB[(PostgreSQL<br/>human_tasks<br/>annotations)]
    CO --> Redis[(Redis<br/>é”åŠ é€Ÿå±‚)]
    CO --> Output[Output<br/>trigger import]
    CO --> Feedback[Feedback<br/>annotation collected]
    CO --> Auth[Auth Module<br/>AnnotatorUser Depends]
    style CO fill:#1a1f2c,stroke:#E879F9,color:#E2E8F4
    style Auth fill:#1a1f2c,stroke:#F59E0B,color:#E2E8F4
```

> **[V1.2 è¡¥å……] è®¤è¯ä¾èµ–**ï¼šæ‰€æœ‰äººå·¥ä»»åŠ¡æ“ä½œç«¯ç‚¹ï¼ˆlock/complete/skip/release/revert/heartbeatï¼‰
> é€šè¿‡ `Depends(AnnotatorUser)` æ³¨å…¥å½“å‰æ ‡æ³¨å‘˜èº«ä»½ï¼Œ`operator` å‚æ•°ä» `user.username` è‡ªåŠ¨è·å–ï¼Œ
> ä¸å†æ¥å—å®¢æˆ·ç«¯ä¼ å…¥ã€‚ç®¡ç†å‘˜è§’è‰²ï¼ˆAdminUserï¼‰äº¦å¯é€šè¿‡æƒé™å®ˆå«ã€‚

---

## 2. ç›®å½•ç»“æ„

```
app/
â”œâ”€â”€ collaboration/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ task_manager.py         # ä»»åŠ¡åˆ›å»º + ä¸Šä¸‹æ–‡å¢å¼º + é‡å…¥ä¸Šé™  [V1.1]
â”‚   â”œâ”€â”€ state_machine.py        # çŠ¶æ€æœº + è½¬æ¢å®ˆå« + å®¡è®¡(å«operator/reason)  [V1.1]
â”‚   â”œâ”€â”€ lock_manager.py         # SKIP LOCKED é¢†å– + å¿ƒè·³(åŸå­æ€§) + è¶…æ—¶é‡Šæ”¾  [V1.1]
â”‚   â”œâ”€â”€ dispatch.py             # æ™ºèƒ½æ´¾å•ï¼ˆèƒ½åŠ›ç”»åƒ+è¯„åˆ†ï¼‰
â”‚   â”œâ”€â”€ timeout_scanner.py      # SLA å››çº§ç†”æ–­æ‰«æ + é€šçŸ¥ + æŠ½æ ·å¤æ ¸  [V1.1]
â”‚   â”œâ”€â”€ annotation_handler.py   # æ ‡æ³¨é‡‡é›† + few-shot åŒæ­¥
â”‚   â”œâ”€â”€ annotator_profiler.py   # [V1.1] æ ‡æ³¨å‘˜ç”»åƒï¼ˆå½’å±æœ¬æ¨¡å—ï¼‰
â”‚   â”œâ”€â”€ context_enricher.py     # [V1.1] ä¸Šä¸‹æ–‡å¢å¼ºï¼ˆè·¨é¡µè™šæ‹Ÿé•¿å›¾ï¼‰
â”‚   â”œâ”€â”€ notification.py         # [V1.1] SLA é€šçŸ¥ï¼ˆä¼å¾®/é’‰é’‰ webhookï¼‰
â”‚   â”œâ”€â”€ api.py                  # REST APIï¼ˆå«è·¨é¡µ SKU å›æº¯ï¼‰  [V1.1]
â”‚   â”œâ”€â”€ schemas.py
â”‚   â”œâ”€â”€ repository.py
â”‚   â””â”€â”€ constants.py
```

---

## 3. ç±»å›¾

```mermaid
classDiagram
    class TaskManager {
        -state_machine: StateMachine
        -dispatcher: SmartDispatcher
        -repo: TaskRepository
        +create_task(job_id, page, type, context) HumanTask
        +complete_task(task_id, result, operator) HumanTask
        +skip_task(task_id, reason, operator) HumanTask
        +revert_task(task_id, operator, reason) HumanTask
        -_enrich_context(job_id, page, context) dict
    }

    class StateMachine {
        +TRANSITIONS: dict
        +transition(task_id, to_status, trigger, operator) void
        -_validate_guard(task, to_status) void
        -_record_audit(entity_type, entity_id, from, to, trigger) void
    }

    class LockManager {
        +acquire(task_id, annotator_id) bool
        +release(task_id) void
        +heartbeat(task_id, annotator_id) void
        +scan_expired_locks() list~str~
    }

    class SmartDispatcher {
        -profiler: AnnotatorProfiler
        +assign(task) str?
        -_score(profile, task_difficulty) float
    }

    class SLAScanner {
        +SLA_POLICY: dict
        +scan_escalation() void
        -_priority_boost(task) void
        -_escalate(task) void
        -_auto_quality_check(task) void
        -_partial_accept(task) void
    }

    class AnnotationHandler {
        +collect(task_id, annotations) void
        +sync_to_few_shot(annotation) void
    }

    TaskManager --> StateMachine
    TaskManager --> SmartDispatcher
    TaskManager --> LockManager
    TaskManager --> AnnotationHandler
```

---

## 4. æ ¸å¿ƒæ—¶åºå›¾

### 4.1 é¢†å– â†’ å®Œæˆ â†’ æ ‡æ³¨é‡‡é›†

```mermaid
sequenceDiagram
    autonumber
    participant Ann as æ ‡æ³¨å‘˜
    participant API as Collaboration API
    participant Lock as LockManager
    participant SM as StateMachine
    participant AH as AnnotationHandler
    participant DB as PostgreSQL
    participant Output as Output Module

    Ann->>+API: POST /tasks/next (é¢†å–ä»»åŠ¡)
    API->>+Lock: acquire_next(annotator_id)
    Lock->>DB: UPDATE human_tasks SET locked_by=:ann,<br/>status='PROCESSING'<br/>WHERE status='CREATED' AND priority=æœ€é«˜<br/>ORDER BY created_at<br/>FOR UPDATE SKIP LOCKED<br/>LIMIT 1<br/>RETURNING *
    DB-->>Lock: task (or NULL)
    Lock-->>-API: HumanTask
    API-->>-Ann: task + enriched context

    loop æ¯ 30 ç§’
        Ann->>API: POST /tasks/{id}/heartbeat
        API->>Lock: heartbeat(task_id, annotator_id)
        Lock->>DB: UPDATE locked_at = now()
    end

    Ann->>+API: POST /tasks/{id}/complete {result, annotations}
    API->>+SM: transition(task_id, COMPLETED, 'complete', ann)
    SM->>DB: UPDATE status='COMPLETED', result=:result
    SM->>DB: INSERT INTO state_transitions
    SM-->>-API: ok

    API->>+AH: collect(task_id, annotations)
    AH->>DB: INSERT INTO annotations (8 ç§ç±»å‹)
    AH->>AH: è¯„ä¼°è´¨é‡ â†’ sync_to_few_shot?
    AH-->>-API: ok

    API->>Output: trigger import for completed SKUs
    API-->>-Ann: success
```

### 4.2 SLA å››çº§ç†”æ–­

```mermaid
flowchart TD
    Start([å®šæ—¶æ‰«æ 60s]) --> L1{CREATED<br/>è¶… 15min?}
    L1 -->|æ˜¯| Boost[priority â†’ HIGH]
    L1 -->|å¦| End

    Boost --> L2{HIGH<br/>è¶… 30min?}
    L2 -->|æ˜¯| Escalate[ESCALATED<br/>é€šçŸ¥ä¸»ç®¡]
    L2 -->|å¦| End

    Escalate --> L3{ESCALATED<br/>è¶… 2h?}
    L3 -->|æ˜¯| AutoCheck{AI confidence<br/>> 0.6?}
    L3 -->|å¦| End

    AutoCheck -->|æ˜¯| Accept[AUTO_SLA å®Œæˆ]
    AutoCheck -->|å¦| L4[priority â†’ AUTO_RESOLVE]

    L4 --> L4Check{AUTO_RESOLVE<br/>è¶… 3h?}
    L4Check -->|æ˜¯| Skip[SKIPPED<br/>ä¸é˜»å¡ Job]
    L4Check -->|å¦| End

    End([ç­‰å¾…ä¸‹æ¬¡æ‰«æ])
    
    style Boost fill:#FFA500,color:#000
    style Escalate fill:#FF6347,color:#FFF
    style Accept fill:#22D3EE,color:#000
    style Skip fill:#8B0000,color:#FFF
```

---

## 5. ç»„ä»¶è¯¦ç»†è§„æ ¼

### 5.1 LockManager â€” SKIP LOCKED

```python
class LockManager:
    """
    é”ç®¡ç†ï¼ˆV1.6:P1-18ï¼‰ï¼š
    - [V1.1 P1-C9] DB ä¸º**å”¯ä¸€**æƒå¨æ¥æºï¼šlocked_by + locked_at åœ¨ human_tasks è¡¨
      æ‰€æœ‰é”åˆ¤å®šä»¥ DB ä¸ºå‡†ï¼ŒRedis ä»…åšæŸ¥è¯¢åŠ é€Ÿå±‚ï¼Œå®ä¾‹é‡å¯ä»¥ DB ä¸ºå‡†ã€‚
    - SKIP LOCKED ç¡®ä¿å¤šå®ä¾‹å¹¶å‘å®‰å…¨
    - å¿ƒè·³ 30sï¼Œè¶…æ—¶ 5min é‡Šæ”¾

    [V1.1] å˜æ›´ï¼š
    - P1-C5: å¿ƒè·³æ›´æ–° DB + Redis åœ¨åŒä¸€äº‹åŠ¡ä¸­ï¼ˆåŸå­æ€§ï¼‰
    - P1-C8: scan_expired_locks å¢åŠ é‡å…¥æ¬¡æ•°æ£€æŸ¥
    """

    HEARTBEAT_INTERVAL = 30   # ç§’
    LOCK_TIMEOUT = 300        # 5 åˆ†é’Ÿ
    MAX_REWORK_COUNT = 5      # [V1.1 P1-C8] é‡å…¥ä¸Šé™

    async def acquire_next(self, annotator_id: str) -> HumanTask | None:
        """SKIP LOCKED é¢†å–ä¼˜å…ˆçº§æœ€é«˜çš„å¾…å¤„ç†ä»»åŠ¡"""
        async with db.begin() as tx:
            row = await tx.execute(text("""
                UPDATE human_tasks
                SET locked_by = :ann, locked_at = now(),
                    status = 'PROCESSING', assigned_to = :ann,
                    assigned_at = now()
                WHERE task_id = (
                    SELECT task_id FROM human_tasks
                    WHERE status IN ('CREATED', 'ESCALATED')
                    ORDER BY
                        CASE priority
                            WHEN 'AUTO_RESOLVE' THEN 0
                            WHEN 'URGENT' THEN 1
                            WHEN 'HIGH' THEN 2
                            WHEN 'NORMAL' THEN 3
                        END,
                        created_at ASC
                    FOR UPDATE SKIP LOCKED
                    LIMIT 1
                )
                RETURNING *
            """), {"ann": annotator_id})
            task = row.fetchone()

            if task:
                # [V1.1 P1-C5] Redis å†™å…¥åœ¨åŒä¸€é€»è¾‘å—å†…ï¼ˆDB å·² commit å³ç”Ÿæ•ˆï¼‰
                await redis.setex(
                    f"task:lock:{task.task_id}", self.LOCK_TIMEOUT, annotator_id)
                await self._record_transition(
                    task.task_id, "CREATED", "PROCESSING", "lock", annotator_id)
        return task

    async def heartbeat(self, task_id: str, annotator_id: str):
        """[V1.1 P1-C5] å¿ƒè·³ï¼šDB æ›´æ–° + Redis ç»­æœŸåœ¨åŒä¸€äº‹åŠ¡å†…"""
        async with db.begin() as tx:
            result = await tx.execute(text("""
                UPDATE human_tasks SET locked_at = now()
                WHERE task_id = :tid AND locked_by = :ann AND status = 'PROCESSING'
                RETURNING task_id
            """), {"tid": task_id, "ann": annotator_id})
            if result.rowcount == 0:
                raise BusinessError("Heartbeat failed: lock lost", "LOCK_LOST")
            # åŒä¸€äº‹åŠ¡æˆåŠŸåå†æ›´æ–° Redis
            await redis.setex(f"task:lock:{task_id}", self.LOCK_TIMEOUT, annotator_id)

    async def scan_expired_locks(self):
        """å®šæ—¶æ‰«æè¶…æ—¶é” â†’ é‡Šæ”¾å›é˜Ÿåˆ— [V1.1 P1-C8 å«é‡å…¥ä¸Šé™]"""
        expired = await db.fetch(text("""
            SELECT task_id, locked_by, rework_count FROM human_tasks
            WHERE status = 'PROCESSING'
              AND locked_at < now() - interval ':timeout seconds'
        """), {"timeout": self.LOCK_TIMEOUT})

        for task in expired:
            # [V1.1 P1-C8] é‡å…¥ä¸Šé™æ£€æŸ¥
            if task.rework_count >= self.MAX_REWORK_COUNT:
                await db.execute(text("""
                    UPDATE human_tasks
                    SET status = 'SKIPPED', locked_by = NULL, locked_at = NULL
                    WHERE task_id = :tid AND status = 'PROCESSING'
                """), {"tid": task.task_id})
                await self._record_transition(
                    task.task_id, "PROCESSING", "SKIPPED",
                    "max_rework_exceeded", "system")
                metrics.human_task_max_rework_total.inc()
            else:
                await db.execute(text("""
                    UPDATE human_tasks
                    SET status = 'CREATED', locked_by = NULL, locked_at = NULL
                    WHERE task_id = :tid AND status = 'PROCESSING'
                """), {"tid": task.task_id})
                await self._record_transition(
                    task.task_id, "PROCESSING", "CREATED", "lock_timeout", "system")
                metrics.human_task_lock_timeout_total.inc()
            await redis.delete(f"task:lock:{task.task_id}")
```

### 5.2 SmartDispatcher â€” æ™ºèƒ½æ´¾å•

```python
class SmartDispatcher:
    """
    æ™ºèƒ½æ´¾å•ï¼ˆT79ï¼‰ï¼š
    - éš¾ä»»åŠ¡ï¼ˆä½ç½®ä¿¡åº¦ < 0.5ï¼‰â†’ ä»…åˆ†é…ç»™é«˜å‡†ç¡®ç‡ï¼ˆâ‰¥ 0.85ï¼‰æ ‡æ³¨å‘˜
    - è¯„åˆ† = quality Ã— 0.6 + load_balance Ã— 0.4
    - æ— åˆé€‚äººé€‰ â†’ Noneï¼ˆè¿›å…¬å…±é˜Ÿåˆ—ï¼‰
    """

    async def assign(self, task: HumanTask) -> str | None:
        difficulty = task.context.get("page_confidence", 0.5)
        available = await self._get_available_annotators()

        scored = []
        for ann in available:
            profile = await self._profiler.get_profile(ann.id)
            if difficulty < 0.5 and profile.accuracy_rate < 0.85:
                continue
            load = 1.0 - min(ann.current_tasks / 10, 1.0)
            score = profile.accuracy_rate * 0.6 + load * 0.4
            scored.append((ann.id, score))

        if not scored:
            return None
        scored.sort(key=lambda x: x[1], reverse=True)
        return scored[0][0]
```

### 5.3 SLA å››çº§ç†”æ–­

```python
SLA_POLICY = {
    "NORMAL":       {"timeout_min": 15,  "action": "PRIORITY_BOOST",     "next": "HIGH"},
    "HIGH":         {"timeout_min": 30,  "action": "ESCALATE_TO_SUPERVISOR", "next": "CRITICAL"},
    "CRITICAL":     {"timeout_min": 120, "action": "AUTO_QUALITY_CHECK",  "next": "AUTO_RESOLVE"},
    "AUTO_RESOLVE": {"timeout_min": 180, "action": "PARTIAL_ACCEPTANCE",  "next": None},
}

class SLAScanner:
    """
    [V1.1] å˜æ›´ï¼š
    - P1-C2: ESCALATE_TO_SUPERVISOR å¢åŠ ä¼å¾®/é’‰é’‰ webhook é€šçŸ¥
    - P1-C6: AUTO_QUALITY_CHECK å®ŒæˆåæŠ½æ · 5% äººå·¥å¤æ ¸
    - P1-C7: AI confidence é˜ˆå€¼ä» Config è¯»å–ï¼ˆéç¡¬ç¼–ç  0.6ï¼‰
    """

    AUTO_REVIEW_SAMPLE_RATE = 0.05  # [V1.1 P1-C6] 5% æŠ½æ ·

    async def scan_escalation(self):
        for level, policy in SLA_POLICY.items():
            stale = await db.fetch(text("""
                SELECT * FROM human_tasks
                WHERE status IN ('CREATED', 'ESCALATED')
                  AND priority = :level
                  AND created_at < now() - interval ':min minutes'
            """), {"level": level, "min": policy["timeout_min"]})

            for task in stale:
                match policy["action"]:
                    case "PRIORITY_BOOST":
                        await self._boost(task, policy["next"])
                    case "ESCALATE_TO_SUPERVISOR":
                        await self._escalate(task)
                    case "AUTO_QUALITY_CHECK":
                        await self._auto_check(task)
                    case "PARTIAL_ACCEPTANCE":
                        await self._partial_accept(task)
                metrics.human_task_escalated_total.labels(
                    action=policy["action"]).inc()

    async def _escalate(self, task):
        """[V1.1 P1-C2] å‡çº§ + é€šçŸ¥ä¸»ç®¡"""
        await db.execute(text("""
            UPDATE human_tasks SET priority = 'CRITICAL'
            WHERE task_id = :tid
        """), {"tid": task.task_id})
        # [V1.1 P1-C2] ä¼å¾®/é’‰é’‰ webhook é€šçŸ¥
        await self._notifier.send(
            channel="supervisor",
            message=f"âš ï¸ ä»»åŠ¡ {task.task_id} è¶…æ—¶ 30min æœªå¤„ç†ï¼Œ"
                    f"Job={task.job_id}, ç±»å‹={task.task_type}",
            level="WARNING")

    async def _auto_check(self, task):
        """L3: AI confidence > é˜ˆå€¼ â†’ è‡ªåŠ¨æ¥å— [V1.1 P1-C7 é˜ˆå€¼é…ç½®åŒ–]"""
        # [V1.1 P1-C7] ä» Config è¯»å–é˜ˆå€¼
        profile = config.get_profile(task.context.get("config_version"))
        auto_accept_threshold = profile.sla_auto_accept_confidence or 0.6

        ai = task.context.get("ai_result", {})
        if ai.get("confidence", 0) > auto_accept_threshold:
            await self._task_mgr.complete_task(
                task.task_id, result=ai, operator="AUTO_SLA")

            # [V1.1 P1-C6] æŠ½æ · 5% äººå·¥å¤æ ¸
            if random.random() < self.AUTO_REVIEW_SAMPLE_RATE:
                await self._create_review_task(task, ai)
                metrics.human_task_auto_review_total.inc()
        else:
            await db.execute(text("""
                UPDATE human_tasks SET priority = 'AUTO_RESOLVE'
                WHERE task_id = :tid
            """), {"tid": task.task_id})

    async def _create_review_task(self, original_task, ai_result):
        """[V1.1 P1-C6] åˆ›å»º AUTO_SLA å¤æ ¸ä»»åŠ¡"""
        await self._task_mgr.create_task(
            job_id=original_task.job_id,
            page_number=original_task.context.get("page_number"),
            task_type="AUTO_SLA_REVIEW",
            context={
                "original_task_id": original_task.task_id,
                "ai_result": ai_result,
                "review_reason": "auto_sla_sample_review",
            },
            priority="HIGH")
```

### 5.4 TaskManager â€” å›é€€/æ’¤é”€

```python
class TaskManager:
    REVERTABLE = {"COMPLETED", "SKIPPED"}
    MAX_REWORK_COUNT = 5  # [V1.1 P1-C8]

    async def revert_task(
        self, task_id: str, operator: str, reason: str
    ) -> HumanTask:
        task = await self._repo.get(task_id)
        if task.status not in self.REVERTABLE:
            raise BusinessError(f"Cannot revert from {task.status}", "TASK_NOT_REVERTABLE")

        # [V1.1 P1-C8] é‡å…¥ä¸Šé™æ£€æŸ¥
        if task.rework_count >= self.MAX_REWORK_COUNT:
            raise BusinessError(
                f"Max rework count ({self.MAX_REWORK_COUNT}) exceeded",
                "MAX_REWORK_EXCEEDED")

        await db.execute(text("""
            UPDATE human_tasks
            SET status = 'CREATED', locked_by = NULL, locked_at = NULL,
                result = NULL, rework_count = rework_count + 1
            WHERE task_id = :tid
        """), {"tid": task_id})
        # [V1.1 P1-C3] å®¡è®¡å¢åŠ  operator + reason
        await self._sm.record_audit(
            "task", task_id, task.status, "CREATED", "revert",
            operator=operator, reason=reason)
        return await self._repo.get(task_id)
```

### 5.5 AnnotatorProfiler â€” æ ‡æ³¨å‘˜ç”»åƒ

```python
class AnnotatorProfiler:
    """
    [V1.1 P1-C10] æ ‡æ³¨å‘˜ç”»åƒç®¡ç†ï¼ˆå½’å± Collaboration æ¨¡å—ï¼‰

    æ•°æ®ç»“æ„ï¼š
    - accuracy_rate: float  â€” å†å²å‡†ç¡®ç‡ï¼ˆ0.0~1.0ï¼‰
    - speed_factor: float   â€” å¹³å‡å®Œæˆé€Ÿåº¦ï¼ˆç›¸å¯¹å€¼ï¼‰
    - specialties: list[str] â€” æ“…é•¿ä»»åŠ¡ç±»å‹
    - total_tasks: int      â€” å†å²ä»»åŠ¡æ€»æ•°
    - reject_rate: float    â€” è¢«ç»„é•¿é€€å›ç‡

    å†·å¯åŠ¨ï¼ˆP1-C10ï¼‰ï¼š
    - æ–°æ ‡æ³¨å‘˜é»˜è®¤ accuracy_rate=0.6ï¼ˆä¿å®ˆä¼°è®¡ï¼‰
    - å‰ 10 ä¸ªä»»åŠ¡éšæœºåˆ†é…ï¼ˆä¸å‚ä¸æ™ºèƒ½æ´¾å•è¯„åˆ†ï¼‰
    - ç¬¬ 11 ä¸ªä»»åŠ¡èµ·ä½¿ç”¨çœŸå®ç”»åƒ

    è¢« SmartDispatcher å’Œ FewShotSyncer ä¾èµ–ã€‚
    """

    DEFAULT_PROFILE = AnnotatorProfile(
        accuracy_rate=0.6,  # [V1.1] Kimi å»ºè®®ä» 0.8 é™è‡³ 0.6 æ›´ä¿å®ˆ
        speed_factor=1.0,
        specialties=[],
        total_tasks=0,
        reject_rate=0.0,
    )
    COLD_START_THRESHOLD = 10

    async def get_profile(self, annotator_id: str) -> AnnotatorProfile:
        profile = await self._repo.get_annotator_profile(annotator_id)
        if not profile:
            return self.DEFAULT_PROFILE
        return profile

    def is_cold_start(self, profile: AnnotatorProfile) -> bool:
        return profile.total_tasks < self.COLD_START_THRESHOLD

    async def refresh_profiles(self):
        """å®šæ—¶ä»»åŠ¡ï¼ˆ1hï¼‰ï¼šæ ¹æ®æœ€è¿‘ 30 å¤©æ ‡æ³¨æ•°æ®åˆ·æ–°ç”»åƒ"""
        annotators = await self._repo.get_active_annotators()
        for ann in annotators:
            stats = await self._repo.compute_annotator_stats(ann.id, days=30)
            await self._repo.update_profile(ann.id, AnnotatorProfile(
                accuracy_rate=stats.accuracy,
                speed_factor=stats.avg_duration_ratio,
                specialties=stats.top_task_types,
                total_tasks=stats.total,
                reject_rate=stats.reject_rate,
            ))
```

### 5.6 ContextEnricher â€” ä¸Šä¸‹æ–‡å¢å¼º

```python
class ContextEnricher:
    """
    [V1.1 P1-C1] è·¨é¡µè¡¨æ ¼è™šæ‹Ÿé•¿å›¾ + ä¸Šä¸‹æ–‡å¢å¼º

    å¯¹äºè·¨é¡µè¡¨æ ¼ä¿®æ­£ä»»åŠ¡ï¼Œæ ‡æ³¨å‘˜éœ€è¦çš„æ˜¯"é€»è¾‘ä¸Šçš„æ•´å¼ è¡¨"ï¼Œ
    è€Œéç‰©ç†ä¸Šçš„å‰åé¡µå›¾ç‰‡ã€‚Pipeline çš„ cross_page_merger å·²æœ‰åˆå¹¶ç»“æœï¼Œ
    åœ¨æ­¤æ„å»ºè™šæ‹Ÿé•¿å›¾ä¼ é€’ç»™ task.contextã€‚
    """

    MAX_CONTEXT_SIZE = 4096  # [V1.1 P1-C4/Kimi] æˆªæ–­ä¸Šé™

    async def enrich(self, job_id: str, page_number: int, context: dict) -> dict:
        # åŸºç¡€ä¸Šä¸‹æ–‡ï¼šå‰åé¡µæˆªå›¾ + æ–‡æ¡£å…¨å±€å±æ€§
        base = await self._build_base_context(job_id, page_number)

        # [V1.1 P1-C1] è·¨é¡µè¡¨æ ¼è™šæ‹Ÿé•¿å›¾
        cross_page = await self._repo.get_cross_page_merge(job_id, page_number)
        if cross_page:
            base["cross_page_table"] = {
                "merged_image_uri": cross_page.merged_image_uri,
                "from_page": cross_page.from_page,
                "to_page": cross_page.to_page,
                "table_header_hash": cross_page.header_hash,
            }

        # [V1.1 P1-C4] binding_candidates é€ä¼ 
        binding_candidates = context.get("binding_candidates")
        if binding_candidates:
            base["binding_candidates"] = binding_candidates

        # æˆªæ–­ä¿æŠ¤
        serialized = json.dumps(base)
        if len(serialized) > self.MAX_CONTEXT_SIZE:
            base.pop("prev_page_screenshot", None)
            base.pop("next_page_screenshot", None)
            logger.warning("context_truncated", job_id=job_id, page=page_number)

        return {**context, **base}
```

---

## 6. å®šæ—¶ä»»åŠ¡

| ä»»åŠ¡ | é—´éš” | é” | è¯´æ˜ |
|------|------|-----|------|
| é”è¶…æ—¶æ‰«æ | 60s | Redis lock + watchdog | é‡Šæ”¾è¶…æ—¶çš„ PROCESSING ä»»åŠ¡ |
| SLA ç†”æ–­æ‰«æ | 60s | Redis lock + watchdog | å››çº§å‡çº§ |
| æ ‡æ³¨å‘˜ç”»åƒåˆ·æ–° | 1h | æ— ï¼ˆå¹‚ç­‰ï¼‰ | åˆ·æ–° annotator_profiles |

---

## 7. Prometheus æŒ‡æ ‡

```python
human_task_created_total = Counter("human_task_created_total", "", ["task_type"])
human_task_completed_total = Counter("human_task_completed_total", "", ["task_type"])
human_task_duration_seconds = Histogram("human_task_duration_seconds", "", ["task_type"])
human_task_queue_length = Gauge("human_task_queue_length", "", ["status", "priority"])
human_task_escalated_total = Counter("human_task_escalated_total", "", ["action"])
human_task_lock_timeout_total = Counter("human_task_lock_timeout_total", "")
human_task_reverted_total = Counter("human_task_reverted_total", "")
# [V1.1] æ–°å¢
human_task_max_rework_total = Counter("human_task_max_rework_total", "Tasks SKIPPED by max rework")
human_task_auto_review_total = Counter("human_task_auto_review_total", "AUTO_SLA sampled for review")
human_task_notification_total = Counter("human_task_notification_total", "", ["channel"])
```

---

## 8. äº¤ä»˜æ¸…å•

| æ–‡ä»¶ | è¡Œæ•°(ä¼°) | ä¼˜å…ˆçº§ | V1.1 å˜æ›´ |
|------|---------|--------|----------|
| `task_manager.py` | ~240 | P0 | +40: é‡å…¥ä¸Šé™ / å®¡è®¡å¢å¼º |
| `state_machine.py` | ~140 | P0 | +20: record_audit å¢åŠ  reason å‚æ•° |
| `lock_manager.py` | ~220 | P0 | +40: å¿ƒè·³åŸå­æ€§ / é‡å…¥ä¸Šé™æ£€æŸ¥ |
| `dispatch.py` | ~120 | P0 | â€” |
| `timeout_scanner.py` | ~230 | P0 | +80: é€šçŸ¥ / æŠ½æ ·å¤æ ¸ / é˜ˆå€¼é…ç½®åŒ– |
| `annotation_handler.py` | ~100 | P0 | â€” |
| `annotator_profiler.py` | ~100 | P1 | ğŸ†• æ–°å¢ |
| `context_enricher.py` | ~80 | P1 | ğŸ†• æ–°å¢ |
| `notification.py` | ~60 | P1 | ğŸ†• æ–°å¢ |
| `api.py` | ~200 | P0 | +50: è·¨é¡µ SKU å›æº¯ API |
| `schemas.py` | ~100 | P0 | +20: AnnotatorProfile / CrossPageContext |
| `repository.py` | ~120 | P0 | +20: ç”»åƒ CRUD |
| `constants.py` | ~40 | P0 | +10: æ–°å¢é…ç½®é¡¹ |
| **æ€»è®¡** | **~1750** | â€” | **+520ï¼ˆV1.0: 1230 â†’ V1.1: 1750ï¼‰** |
